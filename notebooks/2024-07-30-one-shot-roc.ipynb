{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a small tutorial on how to use `rpc.codecs.ROCOneShotArrayCodec` to compress a matrix of shape `(n, d)` where the order between rows is irrelevant.\n",
    "Equivalently, this can be thought of as the set of 1-D arrays corresponding to the rows of the matrix.\n",
    "\n",
    "There are 3 restrictions the matrix must meet in practice:\n",
    "1. Rows must be unique.\n",
    "2. The matrix must be sorted row-wise.\n",
    "3. Auxiliary data must be available at the encoder (e.g., user ids) to remove the initial bits problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faiss.contrib.datasets import DatasetSIFT1M\n",
    "from faiss.contrib.inspect_tools import get_invlist\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "# Build index, remove repetitions (Restriction 1).\n",
    "ds = DatasetSIFT1M()\n",
    "db = ds.get_database()\n",
    "db = np.unique(db, axis=0)\n",
    "queries = ds.get_queries()\n",
    "index = faiss.index_factory(ds.d, f'IVF1000,PQ16x8')\n",
    "index.train(ds.get_train())\n",
    "index.add(db)\n",
    "\n",
    "# Restriction 2: sort database based on codes.\n",
    "# Also, add with external user-generated ids to serve as auxiliary information\n",
    "# in later steps.\n",
    "perm = []\n",
    "for c in range(index.nlist):\n",
    "    I, X = get_invlist(index.invlists, c)\n",
    "    perm_sort = np.lexsort(X[:, ::-1].T)\n",
    "    perm.append(I[perm_sort])\n",
    "perm = np.concatenate(perm)\n",
    "index.reset()\n",
    "\n",
    "ids = rng.integers(0, 1 << 16, size=db.shape[0])\n",
    "index.add_with_ids(db[perm], ids[perm]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll go through the inner workings of `rpc.codecs.ROCOneShotArrayCodec`. First, we sample a permutation with `rpc.codecs.VectorizedPermutationCodec`. Then, we encode the rows of the matrix in the order defined by the sampled permutation.\n",
    "\n",
    "`rpc.codecs.VectorizedPermutationCodec` implements a codec that samples a permutation uniformly at random from the ANS state using a vectorized Lehmer Code.\n",
    "\n",
    "See the overleaf for details on what a Lehmer Code is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpc.codecs import VectorizedPermutationCodec, UniformCodec\n",
    "from rpc.rans import initialize_ans_state\n",
    "from faiss.contrib.inspect_tools import get_invlist\n",
    "import numpy as np\n",
    "\n",
    "# Select a cluster to encode\n",
    "I, X = get_invlist(index.invlists, 23)\n",
    "n, d = X.shape\n",
    "\n",
    "# To facilitate the exposition, we'll pretend `n` is an \n",
    "# integer multiple of `d`. Note that in the actual codec \n",
    "# `rpc.codecs.ROCOneShotArrayCodec` this is not necessary.\n",
    "I = I[:d*(n//d)]\n",
    "X = X[:d*(n//d)]\n",
    "n = X.shape[0]\n",
    "\n",
    "ans_state = initialize_ans_state(shape=(d,))\n",
    "\n",
    "# (Restriction 3) In this example, the user ids serve as the auxiliary data mentioned in the paper.\n",
    "# However, any data can be used.\n",
    "# Encode the auxiliary information in blocks of `d`.\n",
    "for i in range(n//d):\n",
    "    ans_state = UniformCodec(precs=1 << 16).encode(I[d*i: d*(i+1)], ans_state)\n",
    "\n",
    "# Decode a permutation.\n",
    "codec_perm = VectorizedPermutationCodec(n, d)\n",
    "ans_state, perm = codec_perm.decode(ans_state)\n",
    "\n",
    "# Sanity checks.\n",
    "assert np.all(np.sort(perm) == np.arange(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After decoding the permutation, we now just have to reorder the matrix based on this value to encode it into the ANS stack. This is the last step of the encoding procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpc.codecs import UniformCodec\n",
    "\n",
    "row_codec = UniformCodec(precs=256)\n",
    "for i in perm:\n",
    "    ans_state = row_codec.encode(X[i], ans_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding is shown next. First, the permuted version of `X` is decoded from the ANS stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpc.codecs import UniformCodec\n",
    "from rpc.permutations import compute_applied_permutation\n",
    "\n",
    "X_decoded = np.zeros((n, d), dtype=np.uint8)\n",
    "\n",
    "# Decode the rows.\n",
    "for i in reversed(range(n)):\n",
    "    ans_state, X_decoded[i] = row_codec.decode(ans_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point onward, all the rows of the matrix (i.e., the PQ codes) are ready to be used.\n",
    "This algorithm therefore makes the codes available in linear time.\n",
    "\n",
    " Next, the permutation applied to `X` is deduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the decoded rows and recover the sampled permutation\n",
    "perm_decoded = compute_applied_permutation(X_decoded)\n",
    "\n",
    "# Sanity check.\n",
    "assert np.all(perm_decoded == perm)\n",
    "for i in range(n):\n",
    "    assert np.all(X[perm_decoded] == X_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recover the auxiliary data, we need to encode the permutation back onto the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode permutation back onto the stack.\n",
    "ans_state = codec_perm.encode(perm_decoded, ans_state)\n",
    "\n",
    "# Last step: recover the auxiliary information.\n",
    "I_decoded = np.zeros(shape=(n,), dtype=np.int64)\n",
    "for i in reversed(range(n//d)):\n",
    "    ans_state, I_decoded[d*i: d*(i+1)] = UniformCodec(precs=1 << 16).decode(ans_state)\n",
    "\n",
    "# Sanity checks.\n",
    "assert np.all(I == I_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting everything together: `rpc.codecs.ROCOneShotArrayCodec`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the functionalities, except encoding the auxiliary information, is done by a single codec. Next we show how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpc.codecs import ROCOneShotArrayCodec, UniformCodec\n",
    "from rpc.rans import initialize_ans_state\n",
    "from rpc.permutations import compute_applied_permutation\n",
    "\n",
    "# Select a cluster to encode\n",
    "I, X = get_invlist(index.invlists, 23)\n",
    "n, d = X.shape\n",
    "\n",
    "# Encode the auxiliary information in blocks of `d`, and then the last block.\n",
    "ans_state = initialize_ans_state(shape=(d,))\n",
    "for i in range(n//d):\n",
    "    ans_state = UniformCodec(precs=1 << 16).encode(I[d*i: d*(i+1)], ans_state)\n",
    "\n",
    "# Encode the matrix.\n",
    "row_codec = UniformCodec(precs=256)\n",
    "codec = ROCOneShotArrayCodec((n, d), row_codec)\n",
    "ans_state = codec.encode(X, ans_state)\n",
    "\n",
    "# Decode matrix.\n",
    "_, X_decoded = codec.decode(ans_state)\n",
    "\n",
    "# Sanity check.\n",
    "perm = compute_applied_permutation(X_decoded)\n",
    "assert np.all(X[perm] == X_decoded)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_ivf_compression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
